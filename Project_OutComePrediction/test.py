import pandas as pd
import os
import pickle
from sklearn.ensemble import RandomForestClassifier
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.metrics import f1_score
import os

folder = r"C:\Users\Arman Takestani\Downloads\Compressed\predictive-monitoring-benchmark-master\predictive-monitoring-benchmark-master\labeled_logs_csv_processed"
print("ğŸ“‚ Files in folder:")
print(os.listdir(folder))

# Ù…Ø³ÛŒØ± ÙØ§ÛŒÙ„ Ø¯ÛŒØªØ§
log_path = r"C:\Users\Arman Takestani\Downloads\Compressed\predictive-monitoring-benchmark-master\predictive-monitoring-benchmark-master\labeled_logs_csv_processed\Production.csv"
df = pd.read_csv(log_path)

# ÙØ±Ø¶: Ø³ØªÙˆÙ† â€˜labelâ€™ Ù‡Ù…ÙˆÙ† target Ù‡Ø³ØªØŒ Ø§Ú¯Ø± Ø§Ø³Ù…Ø´ ÙØ±Ù‚ Ø¯Ø§Ø±Ù‡ Ø¨Ú¯Ùˆ
X = df.drop(columns=["label"])  
y = df["label"]

# ØªÙ‚Ø³ÛŒÙ… Ø¯Ø§Ø¯Ù‡ Ø¨Ù‡ train/test
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, stratify=y, random_state=42)

# ØªØ¹Ø±ÛŒÙ Ù…Ø¯Ù„ Ùˆ Ù¾Ø§Ø±Ø§Ù…ØªØ±Ù‡Ø§ Ø¨Ø±Ø§ÛŒ Ø¬Ø³ØªØ¬Ùˆ
model = RandomForestClassifier(random_state=42)

param_grid = {
    'n_estimators': [50, 100, 200],
    'max_depth': [5, 10, 20],
    'min_samples_split': [2, 5]
}

grid = GridSearchCV(model, param_grid, cv=3, scoring='f1', verbose=1, n_jobs=-1)
grid.fit(X_train, y_train)

# Ø¨Ù‡ØªØ±ÛŒÙ† Ù¾Ø§Ø±Ø§Ù…ØªØ±
best_params = grid.best_params_

print("âœ… Best params:", best_params)

# Ø°Ø®ÛŒØ±Ù‡ Ù¾Ø§Ø±Ø§Ù…ØªØ± Ø¯Ø± pickle
out_path = r"C:\Users\Arman Takestani\Downloads\Compressed\predictive-monitoring-benchmark-master\best_param_pickles"
os.makedirs(out_path, exist_ok=True)

pickle_path = os.path.join(out_path, "optimal_params_rf_production_prefix_index.pickle")

with open(pickle_path, "wb") as f:
    pickle.dump(best_params, f)

print(f"ğŸ“¦ Best parameters saved to: {pickle_path}")
